{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eed23c1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validate Land Surface Temperature (LST) using interactive widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf466d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries and define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b54ecd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dabeb7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b75d622",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as ipyw\n",
    "import ipyleaflet as ipyl\n",
    "import branca.colormap as cm\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Local imports\n",
    "import land_surface_temperature_retrieval.utils_dashboard as process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba1740",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define Functions:\n",
    "How should the subplots be plotted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a828bdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_choropleth(df, key_column, value_column, metric):\n",
    "    \"\"\" Create an ipyleaflet choropleth layer, from a gpd.GeoDataFrame by defining the key and value column \"\"\"\n",
    "    \n",
    "    # Generate a colormap for the choropleth, based on defined metric\n",
    "    if metric == \"mae\":\n",
    "        vmin, vmax = 1.0, 5.0 #user defined vmin/vmax\n",
    "        cmap = cm.LinearColormap(colors=[\"#fff5f0\", \"#fdbea5\", \"#fc7050\", \"#d42020\", \"#67000d\"],\n",
    "                                 index=process.interpolate_linear(vmin=vmin, vmax=vmax), vmin=vmin, vmax=vmax,\n",
    "                                 caption='mae colormap').to_step(5)\n",
    "    if metric == \"bias\":\n",
    "        vmin, vmax = -5.0, 5.0 #user defined vmin/vmax\n",
    "        cmap = cm.LinearColormap(colors=[\"#0571b0\", \"#92c5de\", \"#f7f7f7\", \"#f4a582\", \"#ca0020\"],\n",
    "                                 index=process.interpolate_linear(vmin=vmin, vmax=vmax, center=0), vmin=vmin, vmax=vmax,\n",
    "                                 caption='bias colormap').to_step(5)\n",
    "    if metric == \"ub_rmse\":\n",
    "        vmin, vmax = 0.0, 5.0 #user defined vmin/vmax\n",
    "        cmap = cm.LinearColormap(colors=[\"#fff5f0\", \"#fdbea5\", \"#fc7050\", \"#d42020\", \"#67000d\"],\n",
    "                                 index=process.interpolate_linear(vmin=vmin, vmax=vmax), vmin=vmin, vmax=vmax,\n",
    "                                 caption='ubRMSE colormap').to_step(5)\n",
    "    if metric == \"r\":\n",
    "        vmin, vmax = 0.7, 1.0\n",
    "        cmap = cm.LinearColormap(colors=[\"#f7fcf5\", \"#caeac3\", \"#7bc87c\", \"#2a924a\", \"#00441b\"],\n",
    "                                 index=process.interpolate_log(vmin=vmin, vmax=vmax), vmin=vmin, vmax=vmax,\n",
    "                                 caption='Pearson r colormap').to_step(5)\n",
    "\n",
    "    df = df.dropna() # NaNs are not understood in the chorpleth, so make sure there are none\n",
    "    \n",
    "    geo_json = json.loads(df[[\"geometry\", key_column, value_column]].to_json()) # convert to a GeoJSON\n",
    "    choro_data = dict(zip(list(map(str, df.index.values)), df[value_column].tolist())) # Create dict with values, for which classes will be created.\n",
    "    geo_json_map = ipyl.Choropleth(geo_data=geo_json, # Plot the choropleth markers\n",
    "                                   choro_data=choro_data, \n",
    "                                   colormap=cmap, \n",
    "                                   key_on=\"id\",\n",
    "                                   value_min=vmin,\n",
    "                                   value_max=vmax,\n",
    "                                   hover_style={'color': 'black', 'fillColor': \"grey\", 'opacity':1, 'fillOpacity': 1},\n",
    "                                   point_style={'radius': 8, 'fillOpacity': 1, 'weight': 3})\n",
    "    \n",
    "    return geo_json_map, vmin, vmax\n",
    "\n",
    "\n",
    "def PlotTimeSeries(stations_df, station, selected_products, t0=datetime(2018, 1, 1), t1=datetime(2018, 12, 31)):\n",
    "    \"\"\" Create a matplotlib figure of the selected time products\"\"\"\n",
    "    # cmap to ensure scatter and line of same product always have the same color\n",
    "    cm = plt.get_cmap('tab20')\n",
    "    \n",
    "    # From the selected products, only plot the ones where the moving average has been taken from:\n",
    "    products = [i for i in selected_products] + [\"roll_\"+i for i in selected_products]\n",
    "    \n",
    "    # Initiate Figure\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    \n",
    "    # Prepare data to be plotted:\n",
    "    row = stations_df.loc[stations_df[\"name\"] == station]\n",
    "    data = dict(zip(products, row[products].iloc[0]))\n",
    "    df = pd.DataFrame(index=row[\"date_time_local\"].iloc[0], data=data, columns=products)\n",
    "    \n",
    "    # Plot the actual values as scatter:\n",
    "    i=0\n",
    "    for product, label in zip(products, selected_products):\n",
    "        df.plot(ax=ax, use_index=True, y=product, label='_nolegend_', style='.', color=cm(i+1), legend=False)\n",
    "        i=i+2\n",
    "    \n",
    "    # Plot the rolled averages as line:\n",
    "    i=0\n",
    "    for product, label in zip(products, selected_products):\n",
    "        df.plot(ax=ax, use_index=True, y=\"roll_\"+product, label=label, color=cm(i), legend=True)\n",
    "        i=i+2    \n",
    "    \n",
    "    # Modify some visualisation settings:\n",
    "    ax.set_xlim(min(row[\"date_time_local\"].iloc[0]), max(row[\"date_time_local\"].iloc[0]))\n",
    "    plt.axvspan(t0, t1, color='grey', alpha=0.2)\n",
    "    ax.set_ylabel(\"Temperature ($^\\circ$C)\")\n",
    "    ax.set_title(station)\n",
    "    ax.grid()\n",
    "    ax.legend(loc='upper left')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def PlotHeatmap(df, station=\"\", sources = [], mode=\"dynamic\", **kwargs):\n",
    "    # Determine Evaluation Metrics for defined station\n",
    "    if mode == \"dynamic\":\n",
    "        table = process.StationTable(df=df, station_name=station, products=sources) #df.loc[station].transpose()\n",
    "    elif mode == \"static\":\n",
    "        table = df.groupby(level=1).mean().transpose() # Spatially averaged metrics\n",
    "    \n",
    "    # Initiate Figure\n",
    "    fig, (ax0, ax1, ax2, ax3) = plt.subplots(nrows=4, ncols=1, figsize=(12,4), sharex=True) \n",
    "    \n",
    "    # Define tick labels\n",
    "    yt = [\"Pearson r\", \"Average\\nbias\", \"MAE\", \"ubRMSE\"]\n",
    "    cols = table.columns.to_list()\n",
    "    cols = [col.replace(\" x \", \"\\nx\\n\") for col in cols]\n",
    "    if mode == \"dynamic\": # Add n observations as well (for dynamic table)\n",
    "        values = list(table.iloc[-1,:])\n",
    "        cols = [col + f\"\\n(n={str(int(value))})\" for col, value in zip(cols, values)]\n",
    "    else:\n",
    "        cols = [col + \"\\n\" for col in cols] # This step is for table allignment purposes\n",
    "        \n",
    "    \n",
    "    # Plot on each ax, and define some visualisation settings\n",
    "    sns.heatmap(data = pd.DataFrame(table.iloc[0,:]).transpose(), ax = ax0, \n",
    "                annot = True, cbar = False, fmt = \".2f\", linewidths = 0.5, yticklabels=[yt[0]], xticklabels=cols,\n",
    "                cmap=\"Reds_r\", vmin=0.7, vmax=1,annot_kws={\"size\": 16, \"weight\": \"bold\"})\n",
    "    sns.heatmap(data = pd.DataFrame(table.iloc[1,:]).transpose(), ax = ax1, \n",
    "                annot = True, cbar = False, fmt = \".2f\", linewidths = 0.5, yticklabels=[yt[1]], xticklabels=cols,\n",
    "                cmap=\"RdBu_r\", center=0,annot_kws={\"size\": 16, \"weight\": \"bold\"})\n",
    "    sns.heatmap(data = pd.DataFrame(table.iloc[2,:]).transpose(), ax = ax2, \n",
    "                annot = True, cbar = False, fmt = \".2f\", linewidths = 0.5, yticklabels=[yt[2]], xticklabels=cols,\n",
    "                cmap=\"Reds\", vmin=0,annot_kws={\"size\": 16, \"weight\": \"bold\"})\n",
    "    sns.heatmap(data = pd.DataFrame(table.iloc[3,:]).transpose(), ax = ax3, \n",
    "                annot = True, cbar = False, fmt = \".2f\", linewidths = 0.5, yticklabels=[yt[3]], xticklabels=cols,\n",
    "                cmap=\"Reds\", vmin=0,annot_kws={\"size\": 16, \"weight\": \"bold\"})\n",
    "    \n",
    "    for ax in [ax0, ax1, ax2, ax3]: # Rotate the labels on each axis, so they appear 'nicer'\n",
    "        ax.set_yticklabels(ax.get_yticklabels(),rotation = 0, fontsize = 16)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize = 16)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def create_legend(vmin, vmax, metric):\n",
    "    \"\"\"Create a colormap legend for (return: ipyleaflet.LegendControl) \"\"\"\n",
    "\n",
    "    # Determine corresponding colors based on chosen metric\n",
    "    if metric == \"bias\":\n",
    "        values = process.interpolate_linear(vmin, vmax)\n",
    "        cmap = [\"#0571b0\", \"#92c5de\", \"#f7f7f7\", \"#f4a582\", \"#ca0020\"] # Manual list of bwr colormap!\n",
    "    elif metric == \"mae\":\n",
    "        values = process.interpolate_linear(vmin, vmax)\n",
    "        cmap = [\"#fff5f0\", \"#fdbea5\", \"#fc7050\", \"#d42020\", \"#67000d\"] # Manual list of reds colormap!\n",
    "    elif metric == \"ub_rmse\":\n",
    "        values = process.interpolate_linear(vmin, vmax)\n",
    "        cmap = [\"#fff5f0\", \"#fdbea5\", \"#fc7050\", \"#d42020\", \"#67000d\"] # Manual list of reds colormap!\n",
    "    elif metric == \"r\":\n",
    "        values = process.interpolate_log(0.7, 1.0)\n",
    "        cmap = [\"#f7fcf5\", \"#caeac3\", \"#7bc87c\", \"#2a924a\", \"#00441b\"] # Manual list of greens colormap!\n",
    "        \n",
    "    values = [str(value) for value in values]\n",
    "    \n",
    "    return ipyl.LegendControl(dict(zip(values, cmap)), \n",
    "                              name=f\"{metric}\", \n",
    "                              position=\"bottomleft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57aa90",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the widgets displayed in the dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e478a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_plot_as_widget(station, products, start_date, end_date):\n",
    "    \"\"\"create timeseries as widget\"\"\"\n",
    "    return ipyw.interactive_output(PlotTimeSeries,\n",
    "                                   {'stations_df': ipyw.fixed(data),\n",
    "                                    'station': ipyw.fixed(station),\n",
    "                                    'selected_products' : ipyw.fixed(products),\n",
    "                                    't0' : ipyw.fixed(start_date),\n",
    "                                    't1' : ipyw.fixed(end_date)})\n",
    "\n",
    "\n",
    "def create_dynamic_table_as_widget(station, df):\n",
    "    \"\"\"create dynamic table as widget\"\"\"\n",
    "    return ipyw.interactive_output(PlotHeatmap,\n",
    "                                   {'df': ipyw.fixed(df),\n",
    "                                    'station': ipyw.fixed(station),\n",
    "                                    'sources': ipyw.fixed(products),\n",
    "                                    'mode': ipyw.fixed(\"dynamic\")})\n",
    "\n",
    "\n",
    "def create_static_table_as_widget():\n",
    "    \"\"\"create static table as widget\"\"\"\n",
    "    return ipyw.interactive_output(PlotHeatmap,\n",
    "                                   {'df': ipyw.fixed(evaluation_df),\n",
    "                                    'sources': ipyw.fixed(products),\n",
    "                                    'mode': ipyw.fixed(\"static\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3eccb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the callback after user interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96388f22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ===== Changes to choropleth =====\n",
    "def update_choropleth(df, new_left, new_right, new_metric):\n",
    "    \"\"\" Update the choropleth and legend layers, depending on the change defined in update_choropleth_product() \"\"\"\n",
    "    \n",
    "    global left_product, right_product, metric # Any update that happens to the data df, left, right or metric variables, should also exist outside this function\n",
    "    \n",
    "    old_choropleth = m.layers[-1] # Identify the old Choropleth layer\n",
    "    \n",
    "\n",
    "    if new_left == new_right: # Avoid Comparing the same thing\n",
    "        print(\"left and right products cannot be the same! \\nNo change applied!\")\n",
    "        return\n",
    "    \n",
    "    try: # First check if left/right combination exists\n",
    "        value = new_metric+\"_\"+f\"{new_left} x {new_right}\"\n",
    "        new_choropleth, vmin, vmax = create_choropleth(df=data, key_column=\"name\", value_column=value, metric=new_metric) # Create new choropleth\n",
    "    except: # If not, check if right/left combination exists\n",
    "        value = new_metric+\"_\"+f\"{new_right} x {new_left}\"\n",
    "        inverted_df = data.copy() # To make sure choropleth is correct, invert values of selected column\n",
    "        if new_metric == \"bias\": \n",
    "            inverted_df[value] = inverted_df[value] * -1.\n",
    "        if new_metric == \"ub_rmse\":\n",
    "            inverted_df = process.inverted_ubrmse(data=inverted_df, left=new_left, right=new_right) # Recalculate ubRMSE\n",
    "        new_choropleth, vmin, vmax = create_choropleth(df=inverted_df, key_column=\"name\", value_column=value, metric=new_metric) # Create new choropleth\n",
    "\n",
    "    legend = create_legend(vmin, vmax, metric=new_metric) # create new legend\n",
    "\n",
    "    new_choropleth.on_click(on_click) # Make sure new choropleth is interactive  \n",
    "    \n",
    "    m.substitute_layer(old_choropleth, new_choropleth) # Replace old with new choropleth\n",
    "    m.remove_control(m.controls[-1]) # Remove old legend\n",
    "    m.add_control(legend) # Add new legend\n",
    "    \n",
    "    print(f\"left: {new_left}, right: {new_right}\")\n",
    "    left_product, right_product, metric = new_left, new_right, new_metric # Make sure the global variables are updated\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def update_choropleth_product(change):\n",
    "    \"\"\" Update the choropleth and legend layers, when left product, right product or evaluation metric is changed \"\"\"\n",
    "    \n",
    "    if change[\"owner\"].description == 'Metric:':\n",
    "        update_choropleth(df=data, new_left=left_product, new_right=right_product, new_metric=change[\"new\"])\n",
    "    elif change[\"owner\"].description == \"Left Product:\":\n",
    "        d = dict(change[\"owner\"].options) # Identify the dict with id's (integers) and labels of dropdown menu\n",
    "        label = (list(d.keys())[list(d.values()).index(change[\"new\"])]) # Get the label corresponds to the selected id\n",
    "        if label == right_product:\n",
    "            print(\"The left and right products cannot be the same!\")\n",
    "            return\n",
    "        update_choropleth(df=data, new_left=label, new_right=right_product, new_metric=metric) # Update the chloropeth\n",
    "    elif change[\"owner\"].description == \"Right Product:\":\n",
    "        d = dict(change[\"owner\"].options) # Identify the dict with id's (integers) and labels of dropdown menu\n",
    "        label = (list(d.keys())[list(d.values()).index(change[\"new\"])]) # Get the label corresponds to the selected id\n",
    "        if label == left_product:\n",
    "            print(\"The left and right products cannot be the same!\")\n",
    "            return\n",
    "        update_choropleth(df=data, new_left=left_product, new_right=label, new_metric=metric) # Update the chloropeth \n",
    "    return\n",
    "\n",
    "\n",
    "# ===== Changes to timeseries =====\n",
    "def on_click(feature=None, **kwargs):\n",
    "    \"\"\" Update timeseries, when a station is clicked \"\"\"\n",
    "    \n",
    "    global station # Make sure that current station is updated outside this function as well, so future changes can rely on the most up to date values.\n",
    "    \n",
    "    try:\n",
    "        station = feature[\"properties\"][\"name\"] # On click, identify the station\n",
    "        print(feature[\"properties\"][\"name\"]) # Log which station has been clicked on\n",
    "        print(time_filtered_df[time_filtered_df[\"name\"] == station][[\"elevation\", \"climate\"]]) # Log station characteristics\n",
    "        plot = create_plot_as_widget(station, products, start_date, end_date) # On click, create timeseries plot\n",
    "        tab_dynamic = create_dynamic_table_as_widget(station=station, df=time_filtered_df) # On click, create dynamic table\n",
    "        rbox.children = (rbox.children[0], rbox.children[1], plot, tab_dynamic)\n",
    "    except TypeError:  # feature is None\n",
    "        pass\n",
    "\n",
    "\n",
    "def update_timeseries_products(change):\n",
    "    \"\"\" Update the timeseries plot, when product selection changes \"\"\"\n",
    "    \n",
    "    global products # Make sure that 'products' are updated outside this function as well, so future changes can rely on the most up to date values.\n",
    "    \n",
    "    # First check if a feature should be added or removed, then add or remove it\n",
    "    if change != change:\n",
    "        pass\n",
    "    elif change[\"new\"]:\n",
    "        products.append(change[\"owner\"].description)\n",
    "    elif not change[\"new\"] and len(products) > 1: # Make sure that the products list never gets smaller than 1, else there is nothing to plot!\n",
    "        products.remove(change[\"owner\"].description)\n",
    "    else:\n",
    "        print(\"At least one item must be selected!\")\n",
    "        return\n",
    "    \n",
    "    products = list(pd.Series(products).unique()) # Make sure there are no duplicate items in list\n",
    "    \n",
    "    try:\n",
    "        plot = create_plot_as_widget(station, products, start_date, end_date) # recreate timeseries plot\n",
    "        if len(products) > 1:\n",
    "            time_filtered_df = process.TimeFilter(df=data, start_date=np.datetime64(start_date), end_date=np.datetime64(end_date)) # Update time filtered df\n",
    "            tab_dynamic = create_dynamic_table_as_widget(station, df=time_filtered_df) # Update dynamic table\n",
    "            rbox.children = (rbox.children[0], rbox.children[1], plot, tab_dynamic)\n",
    "        else: rbox.children = (rbox.children[0], rbox.children[1], plot, rbox.children[-1])\n",
    "    except:\n",
    "        print(\"Something went wrong creating the plot!\")\n",
    "        pass\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def update_timeseries_dates(feature=None):\n",
    "    \"\"\" Update the timeseries plot, when date selection changes \"\"\"\n",
    "    \n",
    "    global start_date, end_date, time_filtered_df # Any update that happens to the start_date, end_date or time_filtered_df, should also exist outside this function\n",
    "    \n",
    "    if feature[\"owner\"].description == \"Start Date:\":\n",
    "        start_date = feature[\"new\"]\n",
    "        print(feature)\n",
    "    elif feature[\"owner\"].description == \"End Date:\":\n",
    "        end_date = feature[\"new\"]\n",
    "        print(feature)\n",
    "\n",
    "    plot = create_plot_as_widget(station, products, start_date=start_date, end_date=end_date) # Recreate timeseries plot\n",
    "    time_filtered_df = process.TimeFilter(df=data, start_date=np.datetime64(start_date), end_date=np.datetime64(end_date)) # Update time filtered df\n",
    "    tab_dynamic = create_dynamic_table_as_widget(station=station, df=time_filtered_df) # Create dynamic table\n",
    "    rbox.children = (rbox.children[0], rbox.children[1], plot, tab_dynamic)\n",
    "    rbox\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def switch_dataframe(change):\n",
    "    \"\"\" When modis is clipped, \"\"\"\n",
    "    global data, data_backup\n",
    "    \n",
    "    if change[\"new\"]: # If selected\n",
    "        data_backup = gpd.GeoDataFrame(columns=data.columns, data=deepcopy(data.values))\n",
    "        data = process.clip_to_col(data, products=products, clipping_col=\"T_modis\")\n",
    "    elif not change[\"new\"]:\n",
    "        data = data_backup\n",
    "    \n",
    "    # Update timeseries and dynamic table, but as no selection changes are made, set the change dict to 'nan'\n",
    "    update_timeseries_products(change=np.nan)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c6c125",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import and reformat the input data (.csv)\n",
    "Define where the input .csv is stored, and also define column names such as the ones with temperature in Kelvin, and those with temperature in Celsius, the date/time column and ones with station specific characteristics (e.g. geometry, station name or elevation). \n",
    "\n",
    "Then, the input .csv is read and the data is pre-processed to the format required for the dashboard. For example, date time columns are converted to datetime.datetime format and filtered to a specified hour, temperature is filtered between -40 and +50 degrees celsius and, if desired, a rolling mean function is applied to the data. The final output is GeoDataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a60f15f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ===== Import Data 1 - Change These Parameters =====\n",
    "# Define data path\n",
    "data_path = os.path.abspath(os.path.join(os.path.dirname( os.getcwd() ), '.', 'data'))\n",
    "ismn_filename = 'data_jupyter_notebook.csv'\n",
    "\n",
    "# Define the column names in the input csv (keys) and their corresponding label to be used (values)\n",
    "dict_col_rename = {\"surface_temperature\":            \"T_uscrn\",\n",
    "                   \"LST_MODIS_V6.1_1000\":            \"T_modis\",\n",
    "                   #\"TEFF-AMSR2-DESC_V003_100\":       \"T_PlanetV3\",\n",
    "                   \"TEFF-AMSR2-DESC_V4.0_1000\":      \"T_PlanetV4\",\n",
    "                   \"LST-S3B-SLSTR-L2-ASC_V1.0_1000\": \"T_S3\" # For shifted values\n",
    "                  }\n",
    "\n",
    "# Define some more column characteristics:\n",
    "celsius_cols = []#[\"T_uscrn\"] # cols with T in celsius\n",
    "kelvin_cols = [\"T_modis\", \"T_PlanetV4\", \"T_S3\", \"T_uscrn\"] # cols with T in Kelvin (\"T_PlanetV3\",)\n",
    "date_time_col = \"date_time_local\"\n",
    "station_info_cols = [\"geometry\", \"name\", \"elevation\", \"climate\", \"landcover\"] # cols with station specific characteristics (should at leas contain 'geometry' and 'name')\n",
    "\n",
    "\n",
    "# ===== Import Data 2 - Do NOT Change These Parameters =====\n",
    "data = process.open_csv(in_csv=os.path.join(data_path, ismn_filename), date_time_col = \"date_time_local\")\n",
    "data.rename(columns=dict_col_rename, inplace=True)\n",
    "data = process.reformat_per_station(data=data,\n",
    "                                        kelvin_cols=kelvin_cols,\n",
    "                                        celsius_cols=celsius_cols,\n",
    "                                        station_info_cols=station_info_cols,\n",
    "                                        date_time_col=date_time_col,\n",
    "                                        hour=2,\n",
    "                                        T_min=-40,\n",
    "                                        T_max=50,\n",
    "                                        add_rolling = True,\n",
    "                                        window=20,\n",
    "                                        min_periods=3\n",
    "                                        )\n",
    "data = process.TemperatureFilter(df=data, products=celsius_cols+kelvin_cols, lower_lim=0, upper_lim=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960a65c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Initial Variables and Pre-process some variables\n",
    "Set the initial states of the dashboard by defining some variables in the cell below. In the second section of the initial variables, the evaluation metrics are pre-calculated for the choropleth map, and the timeseries are clipped to the desired start- and end-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fd83467",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ===== Initial variables 1 - Change These =====\n",
    "products = [\"T_uscrn\", \"T_modis\", \"T_PlanetV4\", \"T_S3\"] # All products we want to consider (\"T_PlanetV3\",)\n",
    "station = \"Aberdeen-35-WNW\" # Station for initial plot\n",
    "left_product = products[2] # Left product to compare in choropleth map\n",
    "right_product = products[0] # Right product to compare in choropleth map\n",
    "metric = \"mae\" # Metric to display in map in initial rendering. Choose from: \"r\", \"bias\", \"ub_rmse\" or \"mae\"\n",
    "start_date = datetime(2020, 9, 1) # Start date of window to calculate metrics over\n",
    "end_date = datetime(2021, 9, 1) # End date of window to calculate metrics over\n",
    "\n",
    "\n",
    "# ===== Initial variables 2 - Do NOT Change These =====\n",
    "evaluation_df = process.EvaluationMetrics(df=data, products=products) # multi-index df with all metrics for all stations\n",
    "data = process.AppendAllMetricCombinations(data, evaluation_df, products, metrics=[\"r\",\"bias\",\"mae\",\"ub_rmse\",\"n\"]) # Append all possible product combinations and metric combinations to the 'data' df\n",
    "dynamic_table = evaluation_df.loc[station].transpose() # Metrics of single station\n",
    "\n",
    "time_filtered_df = process.TimeFilter(data, start_date, end_date) # data df, but arrays filtered to the selected time window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce641d1a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot the interactive dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc54f48",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the dashboard layout (e.g. widgets and buttons), the dasboard behavior (desired callbacks for each button/widget) and plot the dashboard. \n",
    "\n",
    "Note that the timeseries are depicted as the moving average, while the Pearson r, bias and ubRMSE metrics have been determined element-wise. The metrics in the dynamic table (bottom right) are calculated over the selected time window (grey area in timeseries). Since products might have a different amount of valid observations (n), some metrics might not be representative. As a result, the 'clip to modis' option can be utilized as modis is the product that usually has fewest valid observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2eb94f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55480310f5e457ca5144622b6515dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(Dropdown(description='Left Product:', index=2, options=(('T_uscrnâ€¦"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams['font.size'] = 16 # Define the font size of all plots\n",
    "\n",
    "# ===== Initialize map =====\n",
    "m = ipyl.Map(basemap=ipyl.basemaps.OpenTopoMap,\n",
    "             center=(38, -96),\n",
    "             zoom=4,\n",
    "             layout={'width': '750px', 'height': '450px'},\n",
    "             scroll_wheel_zoom=False,\n",
    "             zoom_control=False)\n",
    "m.add_control(ipyl.ZoomControl(position='topright'))\n",
    "m.add_control(ipyl.ScaleControl(position='bottomleft'))\n",
    "m.add_control(ipyl.FullScreenControl())\n",
    "\n",
    "\n",
    "# ===== Initialize buttons, dropdown menu's and date pickers =====\n",
    "metric_buttons = ipyw.ToggleButtons(options=['r','bias', 'mae', 'ub_rmse'], value=metric, description='Metric:', disabled=False, button_style='')\n",
    "dropdown_left = ipyw.Dropdown(options=list(zip(products, range(1, len(products)+1))), value=products.index(left_product)+1, description='Left Product:', style={'description_width': 'initial'})\n",
    "dropdown_right = ipyw.Dropdown(options=list(zip(products, range(1, len(products)+1))), value=products.index(right_product)+1, description='Right Product:', style={'description_width': 'initial'})\n",
    "\n",
    "toggle_products = [ipyw.Checkbox(value=True, description=label, layout=ipyw.Layout(width='40%')) for label in products] # Create checkboxes for products to use\n",
    "toggle_col_clip = ipyw.Checkbox(value=False, description=\"Clip to modis\", layout=ipyw.Layout(width='40%'))\n",
    "date_left = ipyw.DatePicker(description='Start Date:', disabled=False, value = start_date) # Create datepicker for selected start date\n",
    "date_right = ipyw.DatePicker(description='End Date:', disabled=False, value = end_date) # Create datepicker for selected end date\n",
    "\n",
    "\n",
    "# ===== Initialize widgets, layers and controls =====\n",
    "geo_json_map, vmin, vmax = create_choropleth(df=data, key_column=\"name\", value_column=metric+\"_\"+f\"{left_product} x {right_product}\", metric=metric) # Initial choropleth map layer\n",
    "legend = create_legend(vmin, vmax, metric=metric) # Create Legend for choropleth\n",
    "plot = create_plot_as_widget(station, products, start_date=start_date, end_date=end_date) # Timeseries plot\n",
    "tab_static = create_static_table_as_widget() # Static table\n",
    "tab_dynamic = create_dynamic_table_as_widget(station=station, df=time_filtered_df) # Dynamic table\n",
    "\n",
    "\n",
    "# ===== Define dashboard behavior =====\n",
    "m.add_layer(geo_json_map)\n",
    "m.add_control(legend)\n",
    "geo_json_map.on_click(on_click)\n",
    "\n",
    "metric_buttons.observe(update_choropleth_product, \"value\")\n",
    "dropdown_left.observe(update_choropleth_product, \"value\")\n",
    "dropdown_right.observe(update_choropleth_product, \"value\")\n",
    "\n",
    "for p in range(len(products)):\n",
    "    toggle_products[p].observe(update_timeseries_products, \"value\")\n",
    "toggle_col_clip.observe(switch_dataframe, \"value\")\n",
    "date_left.observe(update_timeseries_dates, \"value\")\n",
    "date_right.observe(update_timeseries_dates, \"value\")\n",
    "\n",
    "\n",
    "# ===== Set the layout of the dashboard =====\n",
    "box_layout = ipyw.Layout(display='flex', flex_flow='column', align_items='center', width='100%')\n",
    "\n",
    "lbox = ipyw.VBox([ipyw.HBox([dropdown_left, dropdown_right]), metric_buttons, m, tab_static], layout=box_layout)\n",
    "rbox = ipyw.VBox([ipyw.HBox([date_left, date_right, toggle_col_clip]), ipyw.HBox(children=toggle_products), plot, tab_dynamic], layout=box_layout)\n",
    "hbox = ipyw.HBox([lbox, rbox])\n",
    "hbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5c9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd204a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
